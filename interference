import os
from pathlib import Path
import torch
import numpy as np
from PIL import Image
import segmentation_models_pytorch as smp
import matplotlib.pyplot as plt
from albumentations import Compose, Resize, Normalize, GaussNoise, CoarseDropout, RandomFog, RandomRain, RandomShadow
from albumentations.pytorch import ToTensorV2
from torch.utils.data import Dataset, DataLoader
import lightning.pytorch as pl

CHECKPOINT_PATH = "logs/segmentation_model/version_0/checkpoints/best-model.ckpt"
IMAGE_HEIGHT = 608
IMAGE_WIDTH = 960
BATCH_SIZE = 1
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
NUM_CLASSES = 12
CLASS_COLORS = [
    [0, 0, 0], [128, 64, 128], [70, 70, 70], [153, 153, 153],
    [107, 142, 35], [70, 130, 180], [220, 20, 60], [0, 0, 142],
    [0, 60, 100], [0, 80, 100], [0, 0, 70], [0, 0, 230]
]

TRANSFORM_INTERFERENCE = Compose([
    Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH),
    GaussNoise(var_limit=(10.0, 50.0), p=0.5),
    CoarseDropout(max_holes=5, max_height=1, max_width=IMAGE_WIDTH, fill_value=0, p=0.3),
    CoarseDropout(max_holes=3, max_height=int(IMAGE_HEIGHT*0.2), max_width=int(IMAGE_WIDTH*0.2), fill_value=0, p=0.5),
    RandomFog(fog_coef_lower=0.3, fog_coef_upper=0.6, p=0.3),
    RandomRain(p=0.3),
    RandomShadow(num_shadows_lower=1, num_shadows_upper=2, p=0.3),
    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2()
])

class DatasetInterference(Dataset):
    def __init__(self, folder):
        self.paths = sorted(Path(folder).glob("*.png"))

    def __len__(self):
        return len(self.paths)

    def __getitem__(self, idx):
        path = self.paths[idx]
        image = np.array(Image.open(path).convert("RGB"))
        tensor = TRANSFORM_INTERFERENCE(image=image)["image"]
        return tensor, path.stem

class SegmentationModel(pl.LightningModule):
    def __init__(self):
        super().__init__()
        self.net = smp.DeepLabV3Plus(
            encoder_name='tu-efficientnet_b3',
            encoder_weights=None,
            classes=NUM_CLASSES,
            activation=None
        )

    def forward(self, x):
        return self.net(x)

model = SegmentationModel.load_from_checkpoint(CHECKPOINT_PATH)
model.to(DEVICE).eval()

def visualize_prediction(image_np, mask, output_name, folder="predictions"):
    os.makedirs(folder, exist_ok=True)
    h, w = mask.shape
    colored = np.zeros((h, w, 3), dtype=np.uint8)
    for i in range(NUM_CLASSES):
        colored[mask == i] = CLASS_COLORS[i]
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))
    axes[0].imshow(image_np)
    axes[0].axis('off')
    axes[1].imshow(colored)
    axes[1].axis('off')
    fig.tight_layout()
    fig.savefig(f"{folder}/{output_name}.png")
    plt.close(fig)


def run_inference(folder):
    dataset = DatasetInterference(folder)
    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)
    for tensors, names in loader:
        tensors = tensors.to(DEVICE)
        with torch.no_grad():
            logits = model(tensors)
            preds = torch.argmax(logits, dim=1).cpu().numpy()
        orig = np.array(Image.open(Path(folder)/f"{names[0]}.png").resize((IMAGE_WIDTH, IMAGE_HEIGHT)))
        visualize_prediction(orig, preds[0], names[0])

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_folder", required=True)
    args = parser.parse_args()
    run_inference(args.input_folder)
